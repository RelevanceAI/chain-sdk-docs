---
title: Introduction
description: 'The framework for building LLM powered features, co-pilots and agents.'
---

With advanced customization, magical deployment and multi-provider support, Relevance AI makes it easy to integrate large language models into your product.

<CardGroup cols={2}>
    <Card title="Get started" icon="circle-play" href="/quickstart">
        Build AI features in under 5 mins
    </Card>
    <Card
        title="Library of transformations"
        icon="book"
        href="/reference/transformation-steps"
    >
        The building blocks for your chains
    </Card>
</CardGroup>

## See a demo

Check out how easy it is to build and deploy a PDF Q&A application, in less than 2 minutes.

<iframe
    width="100%"
    height="415"
    src="https://www.youtube.com/embed/tue9Ib9hZ1M?controls=0"
    title="YouTube video player"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen
></iframe>

## Key Features

-   ### Take full control of your LLM

    Our powerful `validators` feature allows you to define schemas that you want from your LLMs. If the LLM doesn't respond with valid data, we will self heal. This means you can build reliable features with LLMs.

-   ### Type safe and flexible SDK

    Our SDK makes it easy to build real applications with LLM powered features. It's provides type hinting for your chains and let's you design every step. We validate types both on compile time _and_ run time in our API.

-   ### Magic deployment to API

    Relevance AI is a fully-managed service that allows you to deploy LLM features in minutes. Don't worry about infrastructure, scaling, or maintenance. Simply `relevance deploy` and your chains are live.

-   ### Multi-provider support

    Relevance AI supports multiple LLM providers, allowing you to quickly switch between any. Integrate once, use anywhere.

-   ### Built-in vector store + integrations

    Relevance AI comes with a built-in [vector store](https://vectordatabase.com) that allows you to store and retrieve vectors for any text. Or, use our integrations to BYO database.

## Common use-cases

Advanced use-cases leveraging LLMs can be built by using chains. These are some of the common ones we see companies get started with. However, what they create after that is as varied and impressive as the product teams building them.

-   Retrieval + Question and Answering
-   Natural language to nQL (SQL, JSON, regex etc)
-   Documentation extraction (PDF to CSV)
-   Recursive chains (Agents)

Here's an example of a business analyst agent built with Relevance AI's SDK.

<iframe
    src="https://www.loom.com/embed/78316ead5b3c4317bf9f0d37abd112bb"
    frameborder="0"
    webkitallowfullscreen
    mozallowfullscreen
    allowfullscreen
    width="100%"
    height="500px"
></iframe>
