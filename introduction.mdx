---
title: Introduction
description: 'The managed, developer-first SDK for building LLM chains.'
---

With advanced customization and multi-provider support, Relevance AI makes it easy to integrate large language models like ChatGPT into your applications.

<CardGroup cols={2}>
    <Card title="Get started" icon="circle-play" href="/quickstart">
        Build AI features in under 5 mins
    </Card>
    <Card title="Features" icon="function" href="/features">
        Dive deep into what makes us special
    </Card>
</CardGroup>
<Card
    title="Library of transformations"
    icon="book"
    href="/sdk/tranformation-steps"
>
    Explore all the transformations available to be used in your chain steps.
</Card>

## Key Features

-   ### Fully-managed service

    Relevance AI is a fully-managed service that allows you to build and deploy LLM chains in minutes. You can use the platform to build and deploy chains without worrying about infrastructure, scaling, or maintenance.

-   ### Multi-provider support

    Relevance AI supports multiple LLM providers, allowing you to quickly switch between any. Integrate once, use anywhere.

-   ### Built-in vector store + integrations

    Relevance AI comes with a built-in [vector store](https://vectordatabase.com) that allows you to store and retrieve vectors for any text. Or, use our integrations to BYO database.

-   ### LLM reliability

    Relevance AI provides a reliable LLM experience by handling all the complexities of LLMs for you. This includes things like quality control, schemas, context management, tokenization, and more.

## Common use-cases

Advanced use-cases leveraging LLMs can be built by using chains. These are some of the common ones we see companies get started with. However, what they create after that is as varied and impressive as the product teams building them.

-   Retrieval + Question and Answering
-   Natural language to nQL (SQL, JSON, regex etc)
-   Documentation extraction (PDF to CSV)
-   Recursive chains (Agents)
